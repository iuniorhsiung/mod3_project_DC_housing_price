{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington DC Housing Market Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "\n",
    "The goal of this analysis is to explore Washington DC housing market data and gather initial findings. From these findings, we will reconfigure and group the Washington DC regions according to various housing statistics. Upon reconfiguration, these regions will then show similar/same sale prices and other housing characteristics. This analysis will be the basis of future evaluation including building predictive models to predict future home sale price and other notable housing market variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    "\n",
    "This analysis uses housing market data from the time period of February 2012 to October 2019, including data for prices (median sale price, percentage of homes sold above list price, percentage of homes that had price drop, etc.), inventory (number of homes on market, new listings, months of supply, etc.), and sales (number of homes sold, median days on market, etc.).\n",
    "\n",
    "#### Data Source: https://www.redfin.com/blog/data-center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Analysis\n",
    "\n",
    "In order to reconfigure the Washington DC regions, we perform multiple hypothesis testings to ensure the certain regions share the same housing charisteristics. In our project, we forcus on three variables: Median Sale Prices, Homes Sold Month-over-Month, and Inventory Month-over-Month. \n",
    "\n",
    "\n",
    "### Testing Methodology:\n",
    "\n",
    "- Two-sample T test with unequal variance to test the means between two regions\n",
    "\n",
    "https://en.wikipedia.org/wiki/Student%27s_t-test\n",
    "\n",
    "- Kolmogorov Smirnov test to test the distributions between two regions\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n",
    "\n",
    "- Wilcoxon Rank test to test the difference for two population mean ranks from two regions\n",
    "\n",
    "https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
    "\n",
    "- Mann-Whitney rank test to test if a random sample from one region is different than another one \n",
    "\n",
    "https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\n",
    "\n",
    "- Kendall Tau test to test if two samples are independent\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient\n",
    "\n",
    "### Assumptions: \n",
    "\n",
    "Based on time-series dataset we have, there is a relationship over time for each feature. Therefore, pratical speaking, we relax our testing assumption that each sample (region) is indepedent within each sample. In addition, we will confirm if two samples are independent of each other based on Kendall Tau test.\n",
    "\n",
    "\n",
    "### Exhaustive Approach:\n",
    "\n",
    "We perform a pairwise test among 82 regions for each testing methodology. Under the current size, there are over 3,300 comparions (82 choose 2). Therefore, we run the tests in a loop based on the 'combine_list'. In addition, there is a concern for the significance level since we use simultaneous hypthesis testing. To resove this, we define our significance level $\\alpha = .000001$ within each test. The significance level would be less than .01 since $( 1-\\alpha)^{10000} > .99$\n",
    "\n",
    "### Rationale for the current approach:\n",
    "\n",
    "In practice, it is difficult to test two time series samples given the nature of dependency. Therefore, as mentioned in the assumption section, we relax the independence assumption. In addition, we will use the results from non-parametric Wilcoxon Rank test, Mann-Whitney rank, Kendall Tau test since we don't want to check the normality assumption from Two-sample T test and Kolmogorov Smirnov test doesn't take time factor into consideration. \n",
    "\n",
    "We will combine the test results from all three non-parametric tests to properly decide which two regions should be combined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import code and libraries from Exploratory Data Analysis. This code takes care of all data imports and data cleaning.\n",
    "\n",
    "%run python_folder/python_files/DC_House_Prices_EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Tests and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Sale Price Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median_sale_price is the final dataset(panda.dataframe) with only median sale price for each region. Say n regions\n",
    "# Create a list combine_list containing any two regions out of n region: list(itertools.combinations(range(A.shape[1]), 2))\n",
    "# Run a loop to perform hypothesis testings: T test, Wilcoxon test, KS test, Mann-Whitney rank test, KS test\n",
    "\n",
    "import itertools\n",
    "from statsmodels.stats.weightstats import ttest_ind as t_test\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ks_2samp \n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kendalltau\n",
    " \n",
    "combine_list = list(itertools.combinations(range(median_sale_price.shape[1]), 2))\n",
    "#statistic, p-value, degree of freedom for two-sample t test\n",
    "t_stat = []\n",
    "p_val_t = []\n",
    "df = []\n",
    "\n",
    "# statistic and p-value for Wilcoxon test \n",
    "non_stat = []\n",
    "p_val_wc = []\n",
    "\n",
    "# statistic and p-value for KS test \n",
    "ks_stat = []\n",
    "p_val_ks = []\n",
    "\n",
    "# statistic and p-value for Mann-Whitney rank test  test \n",
    "mu_stat = []\n",
    "p_val_mu = []\n",
    "\n",
    "# statistic and p-value for Kenndall Tau test\n",
    "kt_stat = []\n",
    "p_val_kt = []\n",
    "\n",
    "for i in range(len(combine_list)):\n",
    "    temp1, temp2, temp3 = t_test(median_sale_price.iloc[:,combine_list[i][0]], median_sale_price.iloc[:,combine_list[i][1]], alternative = \"two-sided\", usevar = \"unequal\")\n",
    "    t_stat.append(float(temp1)) \n",
    "    p_val_t.append(float(temp2))\n",
    "    df.append(float(temp3))\n",
    "    temp4, temp5 = wilcoxon(median_sale_price.iloc[:,combine_list[i][0]], median_sale_price.iloc[:,combine_list[i][1]], alternative = \"two-sided\", zero_method = \"zsplit\")\n",
    "    non_stat.append(float(temp4))\n",
    "    p_val_wc.append(float(temp5)) \n",
    "    temp6, temp7 = ks_2samp(median_sale_price.iloc[:,combine_list[i][0]], median_sale_price.iloc[:,combine_list[i][1]], alternative = \"two-sided\", mode = 'asymp')\n",
    "    ks_stat.append(float(temp6))\n",
    "    p_val_ks.append(float(temp7))\n",
    "    temp8, temp9 = mannwhitneyu(median_sale_price.iloc[:,combine_list[i][0]], median_sale_price.iloc[:,combine_list[i][1]], alternative = \"two-sided\")\n",
    "    mu_stat.append(float(temp8))\n",
    "    p_val_mu.append(float(temp9))\n",
    "    temp10, temp11 = kendalltau(A.iloc[:,combine_list[i][0]], A.iloc[:,combine_list[i][1]])\n",
    "    kt_stat.append(float(temp10))\n",
    "    p_val_kt.append(float(temp11))\n",
    "    \n",
    "test_matrix = pd.DataFrame(list(zip(combine_list, t_stat, p_val_t, df, non_stat, p_val_wc, ks_stat, p_val_ks, mu_stat, p_val_mu, kt_stat, p_val_kt)), \n",
    "               columns =['combinatory', 'Stat_ttest', 'p_ttest', 'df_ttest', 'Stat_wctest', 'p_wctest', 'Stat_kstest', 'p_kstest', 'Stat_mutest', 'p_mutest', 'Stat_kttest', 'p_kttest'])\n",
    "\n",
    "#test_matrix contains the test results for our median_sale_price hypothesis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to detect the hypothesis testing results. 0: reject null, 1: fail to reject null\n",
    "def test_p_value(p = .05, name = 'ttest'):\n",
    "    name_list = []\n",
    "    for i in range(len(test_matrix)):\n",
    "        if test_matrix[\"p_\" + name][i] < p:\n",
    "            name_list.append(0) \n",
    "        else:\n",
    "            name_list.append(1)   \n",
    "    test_matrix['index_' + name] = name_list\n",
    "    \n",
    "    \n",
    "test_p_value(p = .000001, name = 'ttest')\n",
    "test_p_value(p = .000001, name = 'wctest')\n",
    "test_p_value(p = .000001, name = 'kstest')\n",
    "test_p_value(p = .000001, name = 'mutest')\n",
    "test_p_value(p = .000001, name = 'kttest')\n",
    "#test_matrix\n",
    "#test_matrix.shape\n",
    "\n",
    "# Save the final testing results for median_sale_price in data folder\n",
    "test_matrix.to_csv('data/TM_Median Sale Price.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all regions with similar characteristic based on both Wilcoxon and Mann Whitney tests\n",
    "index_wc = test_matrix['index_wctest'] == 1\n",
    "index_mu = test_matrix['index_mutest'] == 1\n",
    "index_kt = test_matrix['index_kttest'] == 0\n",
    "#test_matrix[index_wc]\n",
    "#test_matrix[index_mu]\n",
    "test_matrix[index_wc & index_mu & index_kt][0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find names of matched regions from above cell\n",
    "df_list[1]['Region_1'][0]\n",
    "df_list[18]['Region_18'][0]\n",
    "df_list[35]['Region_35'][0]\n",
    "df_list[65]['Region_65'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data time frame\n",
    "time_frame = pd.date_range('2012-02-01','2019-10-01', \n",
    "              freq='MS').strftime(\"%Y-%b\").tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Sale Price Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of first 8 regions in dataset for visualization purposes, using median_sale_price\n",
    "df_temp = pd.DataFrame(list(zip(time_frame, median_sale_price['Median Sale Price_0'], median_sale_price['Median Sale Price_1'], median_sale_price['Median Sale Price_2'], median_sale_price['Median Sale Price_3'], median_sale_price['Median Sale Price_4'], median_sale_price['Median Sale Price_5'], median_sale_price['Median Sale Price_6'], median_sale_price['Median Sale Price_7'])), \n",
    "               columns =['Time', df_list[0]['Region_0'][0], df_list[1]['Region_1'][0], df_list[2]['Region_2'][0], df_list[3]['Region_3'][0], df_list[4]['Region_4'][0], df_list[5]['Region_5'][0], df_list[6]['Region_6'][0], df_list[7]['Region_7'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of first 8 regions in dataset, using median_sale_price\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,1], label = df_temp.columns[1])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,2], label = df_temp.columns[2])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,3], label = df_temp.columns[3])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,4], label = df_temp.columns[4])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,5], label = df_temp.columns[5])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,6], label = df_temp.columns[6])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,7], label = df_temp.columns[7])\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,8], label = df_temp.columns[8])\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time Series - Median House Price\",fontsize = 25)\n",
    "plt.xlabel(\"Time\", fontsize = 15)\n",
    "plt.ylabel(\"Median House Price\", fontsize = 25)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "plt.xticks(range(5, 100, 12))\n",
    "#plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "#save image of visualization\n",
    "sns_plot.figure.savefig(\"data_visualizations/Time Series - Median House Price.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of 4 matched regions, based on median sale price\n",
    "df_temp = pd.DataFrame(list(zip(time_frame, median_sale_price['Median Sale Price_1'], median_sale_price['Median Sale Price_18'], median_sale_price['Median Sale Price_35'], median_sale_price['Median Sale Price_65'])), \n",
    "               columns =['Time', df_list[1]['Region_1'][0], df_list[18]['Region_18'][0], df_list[35]['Region_35'][0], df_list[65]['Region_65'][0]])\n",
    "#df_temp1 = df_temp.set_index(df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of 4 matched regions, based on median sale price\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,1], label = 'American University Park / Friendship Heights / Tenleytown')\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,2], label = 'Chevy Chase-DC')\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,3], label = 'Foxhall Village')\n",
    "sns_plot = sns.lineplot(df_temp['Time'], df_temp.iloc[:,4], label = 'Southeast Chevy Chase')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time Series - Median House Price\",fontsize = 20)\n",
    "plt.xlabel(\"Time\", fontsize = 20)\n",
    "plt.ylabel(\"Median House Price\", fontsize = 20)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "plt.xticks(range(5, 100, 12))\n",
    "#plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "#save image of visualization\n",
    "sns_plot.figure.savefig(\"data_visualizations/Time Series - Median House Price_Group.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homes Sold Month-over-Month Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homes_sold_mom is the final dataset(panda.dataframe) with only homes sold MoM for each region. Say n regions\n",
    "# Create a list combine_list containing any two regions out of n region: list(itertools.combinations(range(A.shape[1]), 2))\n",
    "# Run a loop to perform hypothesis testings: T test, Wilcoxon test, KS test, Mann-Whitney rank test, KS test \n",
    "\n",
    "import itertools\n",
    "from statsmodels.stats.weightstats import ttest_ind as t_test\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ks_2samp \n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "combine_list = list(itertools.combinations(range(homes_sold_mom.shape[1]), 2))\n",
    "\n",
    "#statistic, p-value, degree of freedom for two-sample t test\n",
    "t_stat = []\n",
    "p_val_t = []\n",
    "df = []\n",
    "\n",
    "# statistic and p-value for Wilcoxon test \n",
    "non_stat = []\n",
    "p_val_wc = []\n",
    "\n",
    "# statistic and p-value for KS test \n",
    "ks_stat = []\n",
    "p_val_ks = []\n",
    "\n",
    "# statistic and p-value for Mann-Whitney rank test  test \n",
    "mu_stat = []\n",
    "p_val_mu = []\n",
    "\n",
    "for i in range(len(combine_list)):\n",
    "    temp1, temp2, temp3 = t_test(homes_sold_mom.iloc[:,combine_list[i][0]], homes_sold_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\", usevar = \"unequal\")\n",
    "    t_stat.append(float(temp1)) \n",
    "    p_val_t.append(float(temp2))\n",
    "    df.append(float(temp3))\n",
    "    temp4, temp5 = wilcoxon(homes_sold_mom.iloc[:,combine_list[i][0]], homes_sold_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\", zero_method = \"zsplit\")\n",
    "    non_stat.append(float(temp4))\n",
    "    p_val_wc.append(float(temp5)) \n",
    "    temp6, temp7 = ks_2samp(homes_sold_mom.iloc[:,combine_list[i][0]], homes_sold_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\", mode = 'asymp')\n",
    "    ks_stat.append(float(temp6))\n",
    "    p_val_ks.append(float(temp7))\n",
    "    temp8, temp9 = mannwhitneyu(homes_sold_mom.iloc[:,combine_list[i][0]], homes_sold_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\")\n",
    "    mu_stat.append(float(temp8))\n",
    "    p_val_mu.append(float(temp9))\n",
    "\n",
    "test_matrix_2 = pd.DataFrame(list(zip(combine_list, t_stat, p_val_t, df, non_stat, p_val_wc, ks_stat, p_val_ks, mu_stat, p_val_mu)), \n",
    "               columns =['combinatory', 'Stat_ttest', 'p_ttest', 'df_ttest', 'Stat_wctest', 'p_wctest', 'Stat_kstest', 'p_kstest', 'Stat_mutest', 'p_mutest'])\n",
    "#test_matrix_2 contains the test results for our homes_sold_mom hypothesis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to detect the hypothesis testing results. 0: reject null, 1: fail to reject null\n",
    "def test_p_value_2(p = .05, name = 'ttest'):\n",
    "    name_list = []\n",
    "    for i in range(len(test_matrix_2)):\n",
    "        if test_matrix_2[\"p_\" + name][i] < p:\n",
    "            name_list.append(0) \n",
    "        else:\n",
    "            name_list.append(1)   \n",
    "    test_matrix_2['index_' + name] = name_list\n",
    "    \n",
    "\n",
    "test_p_value_2(p = .05, name = 'ttest')\n",
    "test_p_value_2(p = .05, name = 'wctest')\n",
    "test_p_value_2(p = .05, name = 'kstest')\n",
    "test_p_value_2(p = .05, name = 'mutest')\n",
    "#(test_matrix_2.index_wctest == 1)\n",
    "\n",
    "\n",
    "# Save the final testing results for homes_sold_mom in data folder\n",
    "test_matrix_2.to_csv('data/TM_Homes Sold MoM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homes Sold Month-over-Month Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of first 8 regions in dataset for visualization purposes, using homes_sold_mom\n",
    "df_temp_2 = pd.DataFrame(list(zip(time_frame, homes_sold_mom['Homes Sold MoM _0'], homes_sold_mom['Homes Sold MoM _1'], homes_sold_mom['Homes Sold MoM _2'], homes_sold_mom['Homes Sold MoM _3'], homes_sold_mom['Homes Sold MoM _4'], homes_sold_mom['Homes Sold MoM _5'], homes_sold_mom['Homes Sold MoM _6'], homes_sold_mom['Homes Sold MoM _7'])), \n",
    "               columns =['Time', df_list[0]['Region_0'][0], df_list[1]['Region_1'][0], df_list[2]['Region_2'][0], df_list[3]['Region_3'][0], df_list[4]['Region_4'][0], df_list[5]['Region_5'][0], df_list[6]['Region_6'][0], df_list[7]['Region_7'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of first 8 regions in dataset, using homes_sold_mom\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,1], label = df_temp_2.columns[1])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,2], label = df_temp_2.columns[2])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,3], label = df_temp_2.columns[3])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,4], label = df_temp_2.columns[4])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,5], label = df_temp_2.columns[5])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,6], label = df_temp_2.columns[6])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,7], label = df_temp_2.columns[7])\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,8], label = df_temp_2.columns[8])\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time Series - Homes Sold Month-over-Month\",fontsize = 15)\n",
    "plt.xlabel(\"Time\", fontsize = 15)\n",
    "plt.ylabel(\"Homes Sold Month-over-Month\", fontsize = 15)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "plt.xticks(range(5, 100, 12))\n",
    "#plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "#save image of visualization\n",
    "sns_plot.figure.savefig(\"data_visualizations/Time Series - Homes Sold Month-over-Month.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of 4 matched regions, based on homes_sold_mom\n",
    "df_temp_2 = pd.DataFrame(list(zip(time_frame, homes_sold_mom['Homes Sold MoM _1'], homes_sold_mom['Homes Sold MoM _18'], homes_sold_mom['Homes Sold MoM _35'], homes_sold_mom['Homes Sold MoM _65'])), \n",
    "               columns =['Time', df_list[1]['Region_1'][0], df_list[18]['Region_18'][0], df_list[35]['Region_35'][0], df_list[65]['Region_65'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of 4 matched regions, based on homes_sold_mom\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,1], label = 'American University Park / Friendship Heights / Tenleytown')\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,2], label = 'Chevy Chase-DC')\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,3], label = 'Foxhall Village')\n",
    "sns_plot = sns.lineplot(df_temp_2['Time'], df_temp_2.iloc[:,4], label = 'Southeast Chevy Chase')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time Series - Homes Sold Month-over-Month\",fontsize = 15)\n",
    "plt.xlabel(\"Time\", fontsize = 15)\n",
    "plt.ylabel(\"Homes Sold Month-over-Month\", fontsize = 15)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "plt.xticks(range(5, 100, 12))\n",
    "#plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "#save image of visualization\n",
    "sns_plot.figure.savefig(\"data_visualizations/Time Series - Homes Sold Month-over-Month_Group.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory Month-over-Month Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory_mom is the final dataset(panda.dataframe) with only inventory MoM for each region. Say n regions\n",
    "# Create a list combine_list containing any two regions out of n region: list(itertools.combinations(range(A.shape[1]), 2))\n",
    "# Run a loop to perform hypothesis testings: T test, Wilcoxon test, KS test, Mann-Whitney rank test, KS test\n",
    "\n",
    "import itertools\n",
    "from statsmodels.stats.weightstats import ttest_ind as t_test\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ks_2samp \n",
    "from scipy.stats import mannwhitneyu\n",
    "combine_list = list(itertools.combinations(range(inventory_mom.shape[1]), 2))\n",
    "\n",
    "#statistic, p-value, degree of freedom for two-sample t test\n",
    "t_stat = []\n",
    "p_val_t = []\n",
    "df = []\n",
    "\n",
    "# statistic and p-value for Wilcoxon test \n",
    "non_stat = []\n",
    "p_val_wc = []\n",
    "\n",
    "# statistic and p-value for KS test \n",
    "ks_stat = []\n",
    "p_val_ks = []\n",
    "\n",
    "# statistic and p-value for Mann-Whitney rank test  test \n",
    "mu_stat = []\n",
    "p_val_mu = []\n",
    "\n",
    "for i in range(len(combine_list)):\n",
    "    temp1, temp2, temp3 = t_test(inventory_mom.iloc[:,combine_list[i][0]], inventory_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\", usevar = \"unequal\")\n",
    "    t_stat.append(float(temp1)) \n",
    "    p_val_t.append(float(temp2))\n",
    "    df.append(float(temp3))\n",
    "    temp4, temp5 = wilcoxon(inventory_mom.iloc[:,combine_list[i][0]], inventory_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\", zero_method = \"zsplit\")\n",
    "    non_stat.append(float(temp4))\n",
    "    p_val_wc.append(float(temp5)) \n",
    "    temp6, temp7 = ks_2samp(inventory_mom.iloc[:,combine_list[i][0]], inventory_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\", mode = 'asymp')\n",
    "    ks_stat.append(float(temp6))\n",
    "    p_val_ks.append(float(temp7))\n",
    "    temp8, temp9 = mannwhitneyu(inventory_mom.iloc[:,combine_list[i][0]], inventory_mom.iloc[:,combine_list[i][1]], alternative = \"two-sided\")\n",
    "    mu_stat.append(float(temp8))\n",
    "    p_val_mu.append(float(temp9))\n",
    "test_matrix_3 = pd.DataFrame(list(zip(combine_list, t_stat, p_val_t, df, non_stat, p_val_wc, ks_stat, p_val_ks, mu_stat, p_val_mu)), \n",
    "               columns =['combinatory', 'Stat_ttest', 'p_ttest', 'df_ttest', 'Stat_wctest', 'p_wctest', 'Stat_kstest', 'p_kstest', 'Stat_mutest', 'p_mutest'])\n",
    "#test_matrix_3 contains the test results for our inventory_mom hypothesis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to detect the hypothesis testing results. 0: reject null, 1: fail to reject null\n",
    "\n",
    "def test_p_value_3(p = .05, name = 'ttest'):\n",
    "    name_list = []\n",
    "    for i in range(len(test_matrix_3)):\n",
    "        if test_matrix_3[\"p_\" + name][i] < p:\n",
    "            name_list.append(0) \n",
    "        else:\n",
    "            name_list.append(1)   \n",
    "    test_matrix_3['index_' + name] = name_list\n",
    "test_p_value_3(p = .05, name = 'ttest')\n",
    "test_p_value_3(p = .05, name = 'wctest')\n",
    "test_p_value_3(p = .05, name = 'kstest')\n",
    "test_p_value_3(p = .05, name = 'mutest')\n",
    "test_matrix_3\n",
    "\n",
    "#save inventory_mom test matrix to data folder\n",
    "test_matrix_3.to_csv('data/TM_Inventory MoM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory Month-over-Month Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of first 8 regions in dataset for visualization purposes, using inventory_mom\n",
    "df_temp_3 = pd.DataFrame(list(zip(time_frame, inventory_mom['Inventory MoM _0'], inventory_mom['Inventory MoM _1'], inventory_mom['Inventory MoM _2'], inventory_mom['Inventory MoM _3'], inventory_mom['Inventory MoM _4'], inventory_mom['Inventory MoM _5'], inventory_mom['Inventory MoM _6'], inventory_mom['Inventory MoM _7'])), \n",
    "               columns =['Time', df_list[0]['Region_0'][0], df_list[1]['Region_1'][0], df_list[2]['Region_2'][0], df_list[3]['Region_3'][0], df_list[4]['Region_4'][0], df_list[5]['Region_5'][0], df_list[6]['Region_6'][0], df_list[7]['Region_7'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of first 8 regions in dataset, using inventory_mom\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,1], label = df_temp_3.columns[1])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,2], label = df_temp_3.columns[2])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,3], label = df_temp_3.columns[3])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,4], label = df_temp_3.columns[4])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,5], label = df_temp_3.columns[5])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,6], label = df_temp_3.columns[6])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,7], label = df_temp_3.columns[7])\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,8], label = df_temp_3.columns[8])\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time Series - Inventory Month-over-Month\",fontsize = 15)\n",
    "plt.xlabel(\"Time\", fontsize = 15)\n",
    "plt.ylabel(\"Inventory Month-over-Month\", fontsize = 15)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "plt.xticks(range(5, 100, 12))\n",
    "#plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "#save image of visualization\n",
    "sns_plot.figure.savefig(\"data_visualizations/Time Series - Inventory Month-over-Month.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset of 4 matched regions, based on inventory_mom\n",
    "df_temp_3 = pd.DataFrame(list(zip(time_frame, inventory_mom['Inventory MoM _1'], inventory_mom['Inventory MoM _18'], inventory_mom['Inventory MoM _35'], inventory_mom['Inventory MoM _65'])), \n",
    "               columns =['Time', df_list[1]['Region_1'][0], df_list[18]['Region_18'][0], df_list[35]['Region_35'][0], df_list[65]['Region_65'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of 4 matched regions, based on inventory_mom\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,1], label = 'American University Park / Friendship Heights / Tenleytown')\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,2], label = 'Chevy Chase-DC')\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,3], label = 'Foxhall Village')\n",
    "sns_plot = sns.lineplot(df_temp_3['Time'], df_temp_3.iloc[:,4], label = 'Southeast Chevy Chase')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Time Series - Inventory Month-over-Month\",fontsize = 15)\n",
    "plt.xlabel(\"Time\", fontsize = 15)\n",
    "plt.ylabel(\"Inventory Month-over-Month\", fontsize = 15)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "plt.xticks(range(5, 100, 12))\n",
    "#plt.xlim()\n",
    "plt.show()\n",
    "\n",
    "#save image of visualization\n",
    "sns_plot.figure.savefig(\"data_visualizations/Time Series - Inventory Month-over-Month_Group.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Conclusions\n",
    "\n",
    "As mentioned previously, we reconfigured regions based on (1) Wilcoxon rank test, (2) Mann-Whitney rank, and (3) Kendall Tau test. First, we confirm if regions are independent based on Kendall Tau test. Next, based on the testing statistics from Wilcoxon rank test, Mann-Whitney rank, we conclude that regions should be reconfigured. There are three housing statistics/features tested in our analysis: Median Home Sale Price, Homes Sold Month-over-Month, and Inventory Month-over-Month. \n",
    "\n",
    "Based on our analysis on Median Home Sale Price, our claim is reassured that some regions share the same home sale prices. For example, four regions should be reconfigured: (1) American University Park / Friendship Heights / Tenleytown, (2) Chevy Chase-DC (3) Foxhall Village, and (4) Southeast Chevy Chase. However, based on the analyses for the Homes Sold Month-over-Month and Inventory Month-over-Month, it is not statistically significant to show that there is a difference among these four regions. Therefore, we recommend that additional investigation be done there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "#### Use Case\n",
    "We can use these initial tests and findings for further analysis in which we can predict future Washington DC housing market statistics and also see what influences Washington DC housing market characteristics over time.\n",
    "\n",
    "#### Next Steps\n",
    "We will use prior yearsâ€™ data to build a predictive model in which we can predict the future home sale prices of the Washington DC housing market, based on regions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
